{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/yliu364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/miniconda3/envs/pytorch/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /hpc2hdd/home/yliu364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Qwen-VL' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/QwenLM/Qwen-VL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/yliu364/Qwen-VL\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.32.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.32.0)\n",
      "Requirement already satisfied: accelerate in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.29.3)\n",
      "Requirement already satisfied: tiktoken in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: einops in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: transformers_stream_generator==0.0.4 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.0.4)\n",
      "Requirement already satisfied: scipy in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.11.3)\n",
      "Requirement already satisfied: torchvision in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.15.2)\n",
      "Requirement already satisfied: pillow in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (10.0.1)\n",
      "Requirement already satisfied: tensorboard in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2.9.0)\n",
      "Requirement already satisfied: matplotlib in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.8.1)\n",
      "Requirement already satisfied: filelock in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (2024.4.16)\n",
      "Requirement already satisfied: requests in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: psutil in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (58.0.4)\n",
      "Requirement already satisfied: wheel in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (0.41.2)\n",
      "Requirement already satisfied: cmake in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.29.2)\n",
      "Requirement already satisfied: lit in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (18.1.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (3.5.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (3.20.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 10)) (2.8.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0->-r requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (2022.6.15)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%cd /hpc2hdd/home/yliu364/Qwen-VL\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepspeed in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (0.14.2)\n",
      "Requirement already satisfied: peft in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: einops_exts in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (0.0.4)\n",
      "Requirement already satisfied: hjson in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: ninja in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (1.11.1.1)\n",
      "Requirement already satisfied: numpy in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from deepspeed) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from deepspeed) (21.3)\n",
      "Requirement already satisfied: psutil in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from deepspeed) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (2.7.1)\n",
      "Requirement already satisfied: pynvml in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (11.5.0)\n",
      "Requirement already satisfied: torch in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from deepspeed) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from deepspeed) (4.66.1)\n",
      "Requirement already satisfied: pyyaml in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: transformers in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from peft) (4.32.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from peft) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from peft) (0.22.2)\n",
      "Requirement already satisfied: einops>=0.4 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from einops_exts) (0.7.0)\n",
      "Requirement already satisfied: filelock in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: requests in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from packaging>=20.0->deepspeed) (3.0.9)\n",
      "Requirement already satisfied: sympy in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch->deepspeed) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from torch->deepspeed) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (58.0.4)\n",
      "Requirement already satisfied: wheel in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (0.41.2)\n",
      "Requirement already satisfied: cmake in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->deepspeed) (3.29.2)\n",
      "Requirement already satisfied: lit in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->deepspeed) (18.1.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from pydantic->deepspeed) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from pydantic->deepspeed) (2.18.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers->peft) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2022.6.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /apps/miniconda3/envs/pytorch/lib/python3.10/site-packages (from sympy->torch->deepspeed) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepspeed peft einops_exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-27 00:16:04,066] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Loading checkpoint shards: 100%|████████████████| 10/10 [01:54<00:00, 11.47s/it]\n",
      "Loading data...\n",
      "Formatting inputs...Skip in lazy mode\n",
      "/hpc2hdd/home/yliu364/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "{'loss': 1.7453, 'learning_rate': 1.25e-06, 'epoch': 0.0}                       \n",
      "{'loss': 1.8602, 'learning_rate': 2.5e-06, 'epoch': 0.01}                       \n",
      "{'loss': 1.6114, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.01}        \n",
      "{'loss': 1.7635, 'learning_rate': 5e-06, 'epoch': 0.01}                         \n",
      "{'loss': 1.594, 'learning_rate': 6.25e-06, 'epoch': 0.01}                       \n",
      "{'loss': 1.5334, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.02}         \n",
      "{'loss': 1.8235, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.02}         \n",
      "{'loss': 1.944, 'learning_rate': 1e-05, 'epoch': 0.02}                          \n",
      "{'loss': 1.702, 'learning_rate': 9.999956368168719e-06, 'epoch': 0.02}          \n",
      "{'loss': 1.8128, 'learning_rate': 9.99982547343637e-06, 'epoch': 0.03}          \n",
      "{'loss': 1.6615, 'learning_rate': 9.999607318087424e-06, 'epoch': 0.03}         \n",
      "{'loss': 1.7414, 'learning_rate': 9.999301905929286e-06, 'epoch': 0.03}         \n",
      "{'loss': 1.5562, 'learning_rate': 9.998909242292234e-06, 'epoch': 0.03}         \n",
      "{'loss': 1.6202, 'learning_rate': 9.998429334029323e-06, 'epoch': 0.04}         \n",
      "{'loss': 1.8283, 'learning_rate': 9.997862189516264e-06, 'epoch': 0.04}         \n",
      "{'loss': 1.7894, 'learning_rate': 9.997207818651273e-06, 'epoch': 0.04}         \n",
      "{'loss': 1.7015, 'learning_rate': 9.996466232854916e-06, 'epoch': 0.04}         \n",
      "{'loss': 1.6585, 'learning_rate': 9.995637445069889e-06, 'epoch': 0.05}         \n",
      "{'loss': 1.7301, 'learning_rate': 9.994721469760802e-06, 'epoch': 0.05}         \n",
      "{'loss': 1.4807, 'learning_rate': 9.99371832291393e-06, 'epoch': 0.05}          \n",
      "{'loss': 1.6021, 'learning_rate': 9.992628022036924e-06, 'epoch': 0.06}         \n",
      "{'loss': 1.7023, 'learning_rate': 9.991450586158515e-06, 'epoch': 0.06}         \n",
      "{'loss': 1.7741, 'learning_rate': 9.990186035828177e-06, 'epoch': 0.06}         \n",
      "{'loss': 1.6169, 'learning_rate': 9.988834393115768e-06, 'epoch': 0.06}         \n",
      "{'loss': 1.6259, 'learning_rate': 9.987395681611145e-06, 'epoch': 0.07}         \n",
      "{'loss': 1.7107, 'learning_rate': 9.985869926423757e-06, 'epoch': 0.07}         \n",
      "{'loss': 1.6369, 'learning_rate': 9.9842571541822e-06, 'epoch': 0.07}           \n",
      "{'loss': 1.6429, 'learning_rate': 9.982557393033758e-06, 'epoch': 0.07}         \n",
      "{'loss': 1.7457, 'learning_rate': 9.980770672643907e-06, 'epoch': 0.08}         \n",
      "{'loss': 1.6167, 'learning_rate': 9.978897024195801e-06, 'epoch': 0.08}         \n",
      "{'loss': 1.8033, 'learning_rate': 9.976936480389723e-06, 'epoch': 0.08}         \n",
      "{'loss': 1.4728, 'learning_rate': 9.97488907544252e-06, 'epoch': 0.08}          \n",
      "{'loss': 1.4364, 'learning_rate': 9.972754845087006e-06, 'epoch': 0.09}         \n",
      "{'loss': 1.5058, 'learning_rate': 9.970533826571329e-06, 'epoch': 0.09}         \n",
      "{'loss': 1.5219, 'learning_rate': 9.968226058658333e-06, 'epoch': 0.09}         \n",
      "{'loss': 1.5846, 'learning_rate': 9.965831581624872e-06, 'epoch': 0.09}         \n",
      "{'loss': 1.4466, 'learning_rate': 9.963350437261115e-06, 'epoch': 0.1}          \n",
      "{'loss': 1.4872, 'learning_rate': 9.960782668869811e-06, 'epoch': 0.1}          \n",
      "{'loss': 1.5702, 'learning_rate': 9.958128321265531e-06, 'epoch': 0.1}          \n",
      "{'loss': 1.3607, 'learning_rate': 9.955387440773902e-06, 'epoch': 0.11}         \n",
      "{'loss': 1.48, 'learning_rate': 9.95256007523077e-06, 'epoch': 0.11}            \n",
      "{'loss': 1.4465, 'learning_rate': 9.949646273981394e-06, 'epoch': 0.11}         \n",
      "{'loss': 1.4006, 'learning_rate': 9.946646087879566e-06, 'epoch': 0.11}         \n",
      "{'loss': 1.4936, 'learning_rate': 9.943559569286731e-06, 'epoch': 0.12}         \n",
      "{'loss': 1.3647, 'learning_rate': 9.940386772071074e-06, 'epoch': 0.12}         \n",
      "{'loss': 1.2458, 'learning_rate': 9.937127751606577e-06, 'epoch': 0.12}         \n",
      "{'loss': 1.3749, 'learning_rate': 9.933782564772049e-06, 'epoch': 0.12}         \n",
      "{'loss': 1.3724, 'learning_rate': 9.930351269950144e-06, 'epoch': 0.13}         \n",
      "{'loss': 1.2578, 'learning_rate': 9.926833927026332e-06, 'epoch': 0.13}         \n",
      "{'loss': 1.3402, 'learning_rate': 9.923230597387856e-06, 'epoch': 0.13}         \n",
      "{'loss': 1.2523, 'learning_rate': 9.919541343922667e-06, 'epoch': 0.13}         \n",
      "{'loss': 1.2462, 'learning_rate': 9.915766231018317e-06, 'epoch': 0.14}         \n",
      "{'loss': 1.3063, 'learning_rate': 9.911905324560844e-06, 'epoch': 0.14}         \n",
      "{'loss': 1.1231, 'learning_rate': 9.907958691933616e-06, 'epoch': 0.14}         \n",
      "{'loss': 1.0002, 'learning_rate': 9.903926402016153e-06, 'epoch': 0.14}         \n",
      "{'loss': 1.3189, 'learning_rate': 9.899808525182935e-06, 'epoch': 0.15}         \n",
      "{'loss': 1.1529, 'learning_rate': 9.895605133302163e-06, 'epoch': 0.15}         \n",
      "{'loss': 1.1313, 'learning_rate': 9.891316299734514e-06, 'epoch': 0.15}         \n",
      "{'loss': 1.1249, 'learning_rate': 9.88694209933185e-06, 'epoch': 0.16}          \n",
      "{'loss': 1.2338, 'learning_rate': 9.882482608435924e-06, 'epoch': 0.16}         \n",
      "{'loss': 1.0376, 'learning_rate': 9.877937904877036e-06, 'epoch': 0.16}         \n",
      "{'loss': 1.0987, 'learning_rate': 9.873308067972679e-06, 'epoch': 0.16}         \n",
      "{'loss': 1.0993, 'learning_rate': 9.868593178526161e-06, 'epoch': 0.17}         \n",
      "{'loss': 0.9932, 'learning_rate': 9.863793318825186e-06, 'epoch': 0.17}         \n",
      "{'loss': 0.9694, 'learning_rate': 9.858908572640422e-06, 'epoch': 0.17}         \n",
      "{'loss': 0.9502, 'learning_rate': 9.853939025224037e-06, 'epoch': 0.17}         \n",
      "{'loss': 1.0113, 'learning_rate': 9.84888476330821e-06, 'epoch': 0.18}          \n",
      "{'loss': 0.9945, 'learning_rate': 9.843745875103628e-06, 'epoch': 0.18}         \n",
      "{'loss': 0.8374, 'learning_rate': 9.838522450297927e-06, 'epoch': 0.18}         \n",
      "{'loss': 0.9098, 'learning_rate': 9.833214580054145e-06, 'epoch': 0.18}         \n",
      "{'loss': 0.9095, 'learning_rate': 9.827822357009123e-06, 'epoch': 0.19}         \n",
      "{'loss': 0.9057, 'learning_rate': 9.822345875271884e-06, 'epoch': 0.19}         \n",
      "{'loss': 0.8435, 'learning_rate': 9.816785230422001e-06, 'epoch': 0.19}         \n",
      "{'loss': 0.8928, 'learning_rate': 9.811140519507922e-06, 'epoch': 0.19}         \n",
      "{'loss': 0.8334, 'learning_rate': 9.805411841045276e-06, 'epoch': 0.2}          \n",
      "{'loss': 0.8895, 'learning_rate': 9.799599295015154e-06, 'epoch': 0.2}          \n",
      "{'loss': 0.9475, 'learning_rate': 9.79370298286237e-06, 'epoch': 0.2}           \n",
      "{'loss': 0.7848, 'learning_rate': 9.787723007493681e-06, 'epoch': 0.21}         \n",
      "{'loss': 0.8486, 'learning_rate': 9.781659473276e-06, 'epoch': 0.21}            \n",
      "{'loss': 0.9498, 'learning_rate': 9.775512486034564e-06, 'epoch': 0.21}         \n",
      "{'loss': 0.9667, 'learning_rate': 9.769282153051099e-06, 'epoch': 0.21}         \n",
      "{'loss': 1.0606, 'learning_rate': 9.762968583061938e-06, 'epoch': 0.22}         \n",
      "{'loss': 0.8792, 'learning_rate': 9.756571886256134e-06, 'epoch': 0.22}         \n",
      "{'loss': 0.9222, 'learning_rate': 9.75009217427352e-06, 'epoch': 0.22}          \n",
      "{'loss': 0.8445, 'learning_rate': 9.74352956020278e-06, 'epoch': 0.22}          \n",
      "{'loss': 0.8083, 'learning_rate': 9.73688415857946e-06, 'epoch': 0.23}          \n",
      "{'loss': 0.8772, 'learning_rate': 9.730156085383979e-06, 'epoch': 0.23}         \n",
      "{'loss': 0.8599, 'learning_rate': 9.723345458039595e-06, 'epoch': 0.23}         \n",
      "{'loss': 0.8273, 'learning_rate': 9.716452395410367e-06, 'epoch': 0.23}         \n",
      "{'loss': 0.8181, 'learning_rate': 9.709477017799076e-06, 'epoch': 0.24}         \n",
      "{'loss': 0.8245, 'learning_rate': 9.702419446945118e-06, 'epoch': 0.24}         \n",
      "{'loss': 0.7286, 'learning_rate': 9.695279806022391e-06, 'epoch': 0.24}         \n",
      "{'loss': 0.7943, 'learning_rate': 9.688058219637137e-06, 'epoch': 0.24}         \n",
      "{'loss': 0.7906, 'learning_rate': 9.680754813825774e-06, 'epoch': 0.25}         \n",
      "{'loss': 0.6375, 'learning_rate': 9.673369716052687e-06, 'epoch': 0.25}         \n",
      "{'loss': 0.7736, 'learning_rate': 9.665903055208013e-06, 'epoch': 0.25}         \n",
      "{'loss': 0.8332, 'learning_rate': 9.658354961605388e-06, 'epoch': 0.26}         \n",
      "{'loss': 0.8133, 'learning_rate': 9.650725566979671e-06, 'epoch': 0.26}         \n",
      "{'loss': 0.9355, 'learning_rate': 9.643015004484641e-06, 'epoch': 0.26}         \n",
      "{'loss': 0.6935, 'learning_rate': 9.635223408690688e-06, 'epoch': 0.26}         \n",
      "{'loss': 0.8149, 'learning_rate': 9.627350915582448e-06, 'epoch': 0.27}         \n",
      "{'loss': 0.6674, 'learning_rate': 9.619397662556434e-06, 'epoch': 0.27}         \n",
      "{'loss': 0.7482, 'learning_rate': 9.611363788418648e-06, 'epoch': 0.27}         \n",
      "{'loss': 0.7489, 'learning_rate': 9.603249433382145e-06, 'epoch': 0.27}         \n",
      "{'loss': 0.6845, 'learning_rate': 9.595054739064591e-06, 'epoch': 0.28}         \n",
      "{'loss': 0.6649, 'learning_rate': 9.586779848485797e-06, 'epoch': 0.28}         \n",
      "{'loss': 0.6162, 'learning_rate': 9.578424906065213e-06, 'epoch': 0.28}         \n",
      "{'loss': 0.6775, 'learning_rate': 9.569990057619414e-06, 'epoch': 0.28}         \n",
      "{'loss': 0.6113, 'learning_rate': 9.561475450359556e-06, 'epoch': 0.29}         \n",
      "{'loss': 0.6793, 'learning_rate': 9.5528812328888e-06, 'epoch': 0.29}           \n",
      "{'loss': 0.7513, 'learning_rate': 9.544207555199722e-06, 'epoch': 0.29}         \n",
      "{'loss': 0.5943, 'learning_rate': 9.535454568671705e-06, 'epoch': 0.29}         \n",
      "{'loss': 0.6897, 'learning_rate': 9.526622426068277e-06, 'epoch': 0.3}          \n",
      "{'loss': 0.7224, 'learning_rate': 9.51771128153446e-06, 'epoch': 0.3}           \n",
      "{'loss': 0.6105, 'learning_rate': 9.50872129059408e-06, 'epoch': 0.3}           \n",
      "{'loss': 0.7057, 'learning_rate': 9.49965261014704e-06, 'epoch': 0.31}          \n",
      "{'loss': 0.641, 'learning_rate': 9.490505398466596e-06, 'epoch': 0.31}          \n",
      "{'loss': 0.5236, 'learning_rate': 9.481279815196587e-06, 'epoch': 0.31}         \n",
      "{'loss': 0.6069, 'learning_rate': 9.471976021348648e-06, 'epoch': 0.31}         \n",
      "{'loss': 0.6759, 'learning_rate': 9.462594179299408e-06, 'epoch': 0.32}         \n",
      "{'loss': 0.5994, 'learning_rate': 9.453134452787643e-06, 'epoch': 0.32}         \n",
      "{'loss': 0.6192, 'learning_rate': 9.443597006911432e-06, 'epoch': 0.32}         \n",
      "{'loss': 0.5272, 'learning_rate': 9.433982008125264e-06, 'epoch': 0.32}         \n",
      "{'loss': 0.7249, 'learning_rate': 9.424289624237143e-06, 'epoch': 0.33}         \n",
      "{'loss': 0.8554, 'learning_rate': 9.414520024405653e-06, 'epoch': 0.33}         \n",
      "{'loss': 0.5483, 'learning_rate': 9.404673379137007e-06, 'epoch': 0.33}         \n",
      "{'loss': 0.5774, 'learning_rate': 9.394749860282068e-06, 'epoch': 0.33}         \n",
      "{'loss': 0.5586, 'learning_rate': 9.384749641033358e-06, 'epoch': 0.34}         \n",
      "{'loss': 0.5765, 'learning_rate': 9.37467289592203e-06, 'epoch': 0.34}          \n",
      "{'loss': 0.5781, 'learning_rate': 9.364519800814818e-06, 'epoch': 0.34}         \n",
      "{'loss': 0.656, 'learning_rate': 9.354290532910977e-06, 'epoch': 0.34}          \n",
      "{'loss': 0.4775, 'learning_rate': 9.343985270739184e-06, 'epoch': 0.35}         \n",
      "{'loss': 0.529, 'learning_rate': 9.333604194154421e-06, 'epoch': 0.35}          \n",
      "{'loss': 0.5153, 'learning_rate': 9.323147484334843e-06, 'epoch': 0.35}         \n",
      "{'loss': 0.689, 'learning_rate': 9.312615323778609e-06, 'epoch': 0.36}          \n",
      "{'loss': 0.5245, 'learning_rate': 9.302007896300697e-06, 'epoch': 0.36}         \n",
      "{'loss': 0.6473, 'learning_rate': 9.291325387029706e-06, 'epoch': 0.36}         \n",
      "{'loss': 0.594, 'learning_rate': 9.280567982404611e-06, 'epoch': 0.36}          \n",
      "{'loss': 0.5375, 'learning_rate': 9.269735870171517e-06, 'epoch': 0.37}         \n",
      "{'loss': 0.6059, 'learning_rate': 9.25882923938038e-06, 'epoch': 0.37}          \n",
      "{'loss': 0.5418, 'learning_rate': 9.247848280381715e-06, 'epoch': 0.37}         \n",
      "{'loss': 0.6871, 'learning_rate': 9.236793184823257e-06, 'epoch': 0.37}         \n",
      "{'loss': 0.5373, 'learning_rate': 9.225664145646633e-06, 'epoch': 0.38}         \n",
      "{'loss': 0.4605, 'learning_rate': 9.214461357083986e-06, 'epoch': 0.38}         \n",
      "{'loss': 0.6319, 'learning_rate': 9.203185014654589e-06, 'epoch': 0.38}         \n",
      "{'loss': 0.5281, 'learning_rate': 9.191835315161432e-06, 'epoch': 0.38}         \n",
      "{'loss': 0.5541, 'learning_rate': 9.180412456687784e-06, 'epoch': 0.39}         \n",
      "{'loss': 0.4916, 'learning_rate': 9.168916638593736e-06, 'epoch': 0.39}         \n",
      "{'loss': 0.5114, 'learning_rate': 9.157348061512728e-06, 'epoch': 0.39}         \n",
      "{'loss': 0.6214, 'learning_rate': 9.14570692734804e-06, 'epoch': 0.39}          \n",
      "{'loss': 0.4849, 'learning_rate': 9.133993439269272e-06, 'epoch': 0.4}          \n",
      "{'loss': 0.4234, 'learning_rate': 9.122207801708802e-06, 'epoch': 0.4}          \n",
      "{'loss': 0.4702, 'learning_rate': 9.110350220358208e-06, 'epoch': 0.4}          \n",
      "{'loss': 0.5102, 'learning_rate': 9.098420902164684e-06, 'epoch': 0.41}         \n",
      "{'loss': 0.4864, 'learning_rate': 9.086420055327431e-06, 'epoch': 0.41}         \n",
      "{'loss': 0.4072, 'learning_rate': 9.074347889294017e-06, 'epoch': 0.41}         \n",
      "{'loss': 0.409, 'learning_rate': 9.062204614756732e-06, 'epoch': 0.41}          \n",
      "{'loss': 0.4031, 'learning_rate': 9.04999044364889e-06, 'epoch': 0.42}          \n",
      "{'loss': 0.4756, 'learning_rate': 9.03770558914116e-06, 'epoch': 0.42}          \n",
      "{'loss': 0.4633, 'learning_rate': 9.025350265637816e-06, 'epoch': 0.42}         \n",
      "{'loss': 0.5645, 'learning_rate': 9.012924688773017e-06, 'epoch': 0.42}         \n",
      "{'loss': 0.4847, 'learning_rate': 9.00042907540703e-06, 'epoch': 0.43}          \n",
      "{'loss': 0.4194, 'learning_rate': 8.987863643622457e-06, 'epoch': 0.43}         \n",
      "{'loss': 0.4924, 'learning_rate': 8.975228612720415e-06, 'epoch': 0.43}         \n",
      "{'loss': 0.3928, 'learning_rate': 8.96252420321672e-06, 'epoch': 0.43}          \n",
      "{'loss': 0.4216, 'learning_rate': 8.94975063683803e-06, 'epoch': 0.44}          \n",
      "{'loss': 0.5528, 'learning_rate': 8.936908136517985e-06, 'epoch': 0.44}         \n",
      "{'loss': 0.4936, 'learning_rate': 8.923996926393306e-06, 'epoch': 0.44}         \n",
      "{'loss': 0.471, 'learning_rate': 8.91101723179989e-06, 'epoch': 0.44}           \n",
      "{'loss': 0.5173, 'learning_rate': 8.897969279268877e-06, 'epoch': 0.45}         \n",
      "{'loss': 0.3946, 'learning_rate': 8.884853296522689e-06, 'epoch': 0.45}         \n",
      "{'loss': 0.5545, 'learning_rate': 8.871669512471068e-06, 'epoch': 0.45}         \n",
      "{'loss': 0.4562, 'learning_rate': 8.858418157207068e-06, 'epoch': 0.46}         \n",
      "{'loss': 0.4047, 'learning_rate': 8.845099462003049e-06, 'epoch': 0.46}         \n",
      "{'loss': 0.3567, 'learning_rate': 8.831713659306635e-06, 'epoch': 0.46}         \n",
      "{'loss': 0.4712, 'learning_rate': 8.818260982736662e-06, 'epoch': 0.46}         \n",
      "{'loss': 0.4456, 'learning_rate': 8.804741667079091e-06, 'epoch': 0.47}         \n",
      "{'loss': 0.3589, 'learning_rate': 8.791155948282927e-06, 'epoch': 0.47}         \n",
      "{'loss': 0.4636, 'learning_rate': 8.777504063456084e-06, 'epoch': 0.47}         \n",
      "{'loss': 0.4184, 'learning_rate': 8.763786250861258e-06, 'epoch': 0.47}         \n",
      "{'loss': 0.4639, 'learning_rate': 8.75000274991176e-06, 'epoch': 0.48}          \n",
      "{'loss': 0.3605, 'learning_rate': 8.736153801167346e-06, 'epoch': 0.48}         \n",
      "{'loss': 0.3584, 'learning_rate': 8.722239646330014e-06, 'epoch': 0.48}         \n",
      "{'loss': 0.3971, 'learning_rate': 8.708260528239788e-06, 'epoch': 0.48}         \n",
      "{'loss': 0.4258, 'learning_rate': 8.694216690870476e-06, 'epoch': 0.49}         \n",
      "{'loss': 0.4828, 'learning_rate': 8.680108379325413e-06, 'epoch': 0.49}         \n",
      "{'loss': 0.3434, 'learning_rate': 8.665935839833191e-06, 'epoch': 0.49}         \n",
      "{'loss': 0.4075, 'learning_rate': 8.651699319743348e-06, 'epoch': 0.49}         \n",
      "{'loss': 0.3854, 'learning_rate': 8.63739906752206e-06, 'epoch': 0.5}           \n",
      "{'loss': 0.3783, 'learning_rate': 8.623035332747804e-06, 'epoch': 0.5}          \n",
      "{'loss': 0.3562, 'learning_rate': 8.608608366107004e-06, 'epoch': 0.5}          \n",
      "{'loss': 0.4386, 'learning_rate': 8.594118419389648e-06, 'epoch': 0.51}         \n",
      "{'loss': 0.3846, 'learning_rate': 8.579565745484899e-06, 'epoch': 0.51}         \n",
      "{'loss': 0.3795, 'learning_rate': 8.564950598376683e-06, 'epoch': 0.51}         \n",
      "{'loss': 0.375, 'learning_rate': 8.550273233139252e-06, 'epoch': 0.51}          \n",
      "{'loss': 0.4098, 'learning_rate': 8.535533905932739e-06, 'epoch': 0.52}         \n",
      "{'loss': 0.3326, 'learning_rate': 8.520732873998675e-06, 'epoch': 0.52}         \n",
      "{'loss': 0.3722, 'learning_rate': 8.505870395655512e-06, 'epoch': 0.52}         \n",
      "{'loss': 0.4094, 'learning_rate': 8.490946730294112e-06, 'epoch': 0.52}         \n",
      "{'loss': 0.3633, 'learning_rate': 8.475962138373212e-06, 'epoch': 0.53}         \n",
      "{'loss': 0.3703, 'learning_rate': 8.460916881414886e-06, 'epoch': 0.53}         \n",
      "{'loss': 0.3532, 'learning_rate': 8.445811221999983e-06, 'epoch': 0.53}         \n",
      "{'loss': 0.5048, 'learning_rate': 8.430645423763533e-06, 'epoch': 0.53}         \n",
      "{'loss': 0.4289, 'learning_rate': 8.415419751390155e-06, 'epoch': 0.54}         \n",
      "{'loss': 0.3513, 'learning_rate': 8.400134470609438e-06, 'epoch': 0.54}         \n",
      "{'loss': 0.2946, 'learning_rate': 8.3847898481913e-06, 'epoch': 0.54}           \n",
      "{'loss': 0.3511, 'learning_rate': 8.36938615194133e-06, 'epoch': 0.54}          \n",
      "{'loss': 0.407, 'learning_rate': 8.353923650696119e-06, 'epoch': 0.55}          \n",
      "{'loss': 0.3913, 'learning_rate': 8.338402614318563e-06, 'epoch': 0.55}         \n",
      "{'loss': 0.3054, 'learning_rate': 8.322823313693162e-06, 'epoch': 0.55}         \n",
      "{'loss': 0.4605, 'learning_rate': 8.307186020721281e-06, 'epoch': 0.56}         \n",
      "{'loss': 0.3346, 'learning_rate': 8.291491008316409e-06, 'epoch': 0.56}         \n",
      "{'loss': 0.3153, 'learning_rate': 8.275738550399402e-06, 'epoch': 0.56}         \n",
      "{'loss': 0.4126, 'learning_rate': 8.259928921893694e-06, 'epoch': 0.56}         \n",
      "{'loss': 0.4121, 'learning_rate': 8.244062398720503e-06, 'epoch': 0.57}         \n",
      "{'loss': 0.316, 'learning_rate': 8.228139257794012e-06, 'epoch': 0.57}          \n",
      "{'loss': 0.4295, 'learning_rate': 8.212159777016543e-06, 'epoch': 0.57}         \n",
      "{'loss': 0.3485, 'learning_rate': 8.196124235273698e-06, 'epoch': 0.57}         \n",
      "{'loss': 0.3619, 'learning_rate': 8.180032912429497e-06, 'epoch': 0.58}         \n",
      "{'loss': 0.385, 'learning_rate': 8.163886089321493e-06, 'epoch': 0.58}          \n",
      "{'loss': 0.3481, 'learning_rate': 8.147684047755873e-06, 'epoch': 0.58}         \n",
      "{'loss': 0.3696, 'learning_rate': 8.131427070502535e-06, 'epoch': 0.58}         \n",
      "{'loss': 0.4125, 'learning_rate': 8.115115441290151e-06, 'epoch': 0.59}         \n",
      "{'loss': 0.3933, 'learning_rate': 8.098749444801226e-06, 'epoch': 0.59}         \n",
      "{'loss': 0.3889, 'learning_rate': 8.082329366667115e-06, 'epoch': 0.59}         \n",
      "{'loss': 0.3742, 'learning_rate': 8.065855493463055e-06, 'epoch': 0.59}         \n",
      "{'loss': 0.428, 'learning_rate': 8.049328112703144e-06, 'epoch': 0.6}           \n",
      "{'loss': 0.3306, 'learning_rate': 8.032747512835338e-06, 'epoch': 0.6}          \n",
      "{'loss': 0.3518, 'learning_rate': 8.016113983236413e-06, 'epoch': 0.6}          \n",
      "{'loss': 0.2866, 'learning_rate': 7.999427814206911e-06, 'epoch': 0.61}         \n",
      "{'loss': 0.3677, 'learning_rate': 7.982689296966079e-06, 'epoch': 0.61}         \n",
      "{'loss': 0.3164, 'learning_rate': 7.965898723646777e-06, 'epoch': 0.61}         \n",
      "{'loss': 0.2911, 'learning_rate': 7.949056387290392e-06, 'epoch': 0.61}         \n",
      "{'loss': 0.3107, 'learning_rate': 7.932162581841715e-06, 'epoch': 0.62}         \n",
      "{'loss': 0.38, 'learning_rate': 7.915217602143814e-06, 'epoch': 0.62}           \n",
      "{'loss': 0.4554, 'learning_rate': 7.898221743932887e-06, 'epoch': 0.62}         \n",
      "{'loss': 0.414, 'learning_rate': 7.881175303833102e-06, 'epoch': 0.62}          \n",
      "{'loss': 0.4036, 'learning_rate': 7.864078579351418e-06, 'epoch': 0.63}         \n",
      "{'loss': 0.3255, 'learning_rate': 7.84693186887239e-06, 'epoch': 0.63}          \n",
      "{'loss': 0.3938, 'learning_rate': 7.829735471652978e-06, 'epoch': 0.63}         \n",
      "{'loss': 0.3192, 'learning_rate': 7.812489687817294e-06, 'epoch': 0.63}         \n",
      "{'loss': 0.2998, 'learning_rate': 7.795194818351395e-06, 'epoch': 0.64}         \n",
      "{'loss': 0.3263, 'learning_rate': 7.777851165098012e-06, 'epoch': 0.64}         \n",
      "{'loss': 0.3471, 'learning_rate': 7.760459030751285e-06, 'epoch': 0.64}         \n",
      "{'loss': 0.3436, 'learning_rate': 7.743018718851481e-06, 'epoch': 0.64}         \n",
      "{'loss': 0.3347, 'learning_rate': 7.7255305337797e-06, 'epoch': 0.65}           \n",
      "{'loss': 0.3309, 'learning_rate': 7.70799478075256e-06, 'epoch': 0.65}          \n",
      "{'loss': 0.3754, 'learning_rate': 7.690411765816864e-06, 'epoch': 0.65}         \n",
      "{'loss': 0.3526, 'learning_rate': 7.672781795844271e-06, 'epoch': 0.66}         \n",
      "{'loss': 0.3392, 'learning_rate': 7.655105178525932e-06, 'epoch': 0.66}         \n",
      "{'loss': 0.3295, 'learning_rate': 7.637382222367118e-06, 'epoch': 0.66}         \n",
      "{'loss': 0.3372, 'learning_rate': 7.619613236681845e-06, 'epoch': 0.66}         \n",
      "{'loss': 0.4565, 'learning_rate': 7.601798531587465e-06, 'epoch': 0.67}         \n",
      "{'loss': 0.4483, 'learning_rate': 7.583938417999261e-06, 'epoch': 0.67}         \n",
      "{'loss': 0.4109, 'learning_rate': 7.566033207625021e-06, 'epoch': 0.67}         \n",
      "{'loss': 0.2475, 'learning_rate': 7.548083212959588e-06, 'epoch': 0.67}         \n",
      "{'loss': 0.2772, 'learning_rate': 7.53008874727942e-06, 'epoch': 0.68}          \n",
      "{'loss': 0.3768, 'learning_rate': 7.512050124637114e-06, 'epoch': 0.68}         \n",
      "{'loss': 0.3116, 'learning_rate': 7.493967659855922e-06, 'epoch': 0.68}         \n",
      "{'loss': 0.3733, 'learning_rate': 7.475841668524268e-06, 'epoch': 0.68}         \n",
      "{'loss': 0.3224, 'learning_rate': 7.457672466990231e-06, 'epoch': 0.69}         \n",
      "{'loss': 0.3101, 'learning_rate': 7.439460372356025e-06, 'epoch': 0.69}         \n",
      "{'loss': 0.2964, 'learning_rate': 7.421205702472464e-06, 'epoch': 0.69}         \n",
      "{'loss': 0.3718, 'learning_rate': 7.402908775933419e-06, 'epoch': 0.69}         \n",
      "{'loss': 0.2966, 'learning_rate': 7.3845699120702585e-06, 'epoch': 0.7}         \n",
      "{'loss': 0.3058, 'learning_rate': 7.366189430946262e-06, 'epoch': 0.7}          \n",
      "{'loss': 0.2905, 'learning_rate': 7.347767653351054e-06, 'epoch': 0.7}          \n",
      "{'loss': 0.2775, 'learning_rate': 7.329304900794991e-06, 'epoch': 0.71}         \n",
      "{'loss': 0.2734, 'learning_rate': 7.310801495503555e-06, 'epoch': 0.71}         \n",
      "{'loss': 0.3318, 'learning_rate': 7.292257760411726e-06, 'epoch': 0.71}         \n",
      "{'loss': 0.2991, 'learning_rate': 7.273674019158356e-06, 'epoch': 0.71}         \n",
      "{'loss': 0.3321, 'learning_rate': 7.25505059608051e-06, 'epoch': 0.72}          \n",
      "{'loss': 0.3467, 'learning_rate': 7.236387816207808e-06, 'epoch': 0.72}         \n",
      "{'loss': 0.3474, 'learning_rate': 7.217686005256755e-06, 'epoch': 0.72}         \n",
      "{'loss': 0.3086, 'learning_rate': 7.198945489625054e-06, 'epoch': 0.72}         \n",
      "{'loss': 0.3241, 'learning_rate': 7.180166596385915e-06, 'epoch': 0.73}         \n",
      "{'loss': 0.2578, 'learning_rate': 7.161349653282335e-06, 'epoch': 0.73}         \n",
      "{'loss': 0.2833, 'learning_rate': 7.14249498872139e-06, 'epoch': 0.73}          \n",
      "{'loss': 0.3689, 'learning_rate': 7.123602931768498e-06, 'epoch': 0.73}         \n",
      "{'loss': 0.2839, 'learning_rate': 7.104673812141676e-06, 'epoch': 0.74}         \n",
      "{'loss': 0.3366, 'learning_rate': 7.085707960205783e-06, 'epoch': 0.74}         \n",
      "{'loss': 0.2531, 'learning_rate': 7.0667057069667625e-06, 'epoch': 0.74}        \n",
      "{'loss': 0.4165, 'learning_rate': 7.047667384065855e-06, 'epoch': 0.74}         \n",
      "{'loss': 0.3934, 'learning_rate': 7.028593323773819e-06, 'epoch': 0.75}         \n",
      "{'loss': 0.3452, 'learning_rate': 7.0094838589851265e-06, 'epoch': 0.75}        \n",
      "{'loss': 0.3103, 'learning_rate': 6.990339323212154e-06, 'epoch': 0.75}         \n",
      "{'loss': 0.3639, 'learning_rate': 6.971160050579366e-06, 'epoch': 0.76}         \n",
      "{'loss': 0.3142, 'learning_rate': 6.9519463758174745e-06, 'epoch': 0.76}        \n",
      "{'loss': 0.3153, 'learning_rate': 6.932698634257608e-06, 'epoch': 0.76}         \n",
      "{'loss': 0.2961, 'learning_rate': 6.913417161825449e-06, 'epoch': 0.76}         \n",
      "{'loss': 0.3107, 'learning_rate': 6.8941022950353816e-06, 'epoch': 0.77}        \n",
      "{'loss': 0.2745, 'learning_rate': 6.8747543709846064e-06, 'epoch': 0.77}        \n",
      "{'loss': 0.3035, 'learning_rate': 6.855373727347268e-06, 'epoch': 0.77}         \n",
      "{'loss': 0.2418, 'learning_rate': 6.8359607023685544e-06, 'epoch': 0.77}        \n",
      "{'loss': 0.3129, 'learning_rate': 6.8165156348588e-06, 'epoch': 0.78}           \n",
      "{'loss': 0.3563, 'learning_rate': 6.797038864187564e-06, 'epoch': 0.78}         \n",
      "{'loss': 0.3403, 'learning_rate': 6.7775307302777194e-06, 'epoch': 0.78}        \n",
      "{'loss': 0.2686, 'learning_rate': 6.757991573599504e-06, 'epoch': 0.78}         \n",
      "{'loss': 0.3093, 'learning_rate': 6.738421735164595e-06, 'epoch': 0.79}         \n",
      "{'loss': 0.2971, 'learning_rate': 6.718821556520151e-06, 'epoch': 0.79}         \n",
      "{'loss': 0.3212, 'learning_rate': 6.699191379742842e-06, 'epoch': 0.79}         \n",
      "{'loss': 0.2728, 'learning_rate': 6.679531547432896e-06, 'epoch': 0.79}         \n",
      "{'loss': 0.2986, 'learning_rate': 6.659842402708105e-06, 'epoch': 0.8}          \n",
      "{'loss': 0.2903, 'learning_rate': 6.640124289197845e-06, 'epoch': 0.8}          \n",
      "{'loss': 0.2249, 'learning_rate': 6.620377551037082e-06, 'epoch': 0.8}          \n",
      "{'loss': 0.3117, 'learning_rate': 6.600602532860349e-06, 'epoch': 0.8}          \n",
      "{'loss': 0.3362, 'learning_rate': 6.580799579795751e-06, 'epoch': 0.81}         \n",
      "{'loss': 0.3136, 'learning_rate': 6.560969037458933e-06, 'epoch': 0.81}         \n",
      "{'loss': 0.2429, 'learning_rate': 6.541111251947043e-06, 'epoch': 0.81}         \n",
      "{'loss': 0.3267, 'learning_rate': 6.521226569832699e-06, 'epoch': 0.82}         \n",
      "{'loss': 0.3142, 'learning_rate': 6.501315338157942e-06, 'epoch': 0.82}         \n",
      "{'loss': 0.262, 'learning_rate': 6.481377904428171e-06, 'epoch': 0.82}          \n",
      "{'loss': 0.3181, 'learning_rate': 6.461414616606083e-06, 'epoch': 0.82}         \n",
      "{'loss': 0.3104, 'learning_rate': 6.441425823105603e-06, 'epoch': 0.83}         \n",
      "{'loss': 0.332, 'learning_rate': 6.421411872785794e-06, 'epoch': 0.83}          \n",
      "{'loss': 0.2544, 'learning_rate': 6.401373114944781e-06, 'epoch': 0.83}         \n",
      "{'loss': 0.344, 'learning_rate': 6.381309899313642e-06, 'epoch': 0.83}          \n",
      "{'loss': 0.3109, 'learning_rate': 6.361222576050312e-06, 'epoch': 0.84}         \n",
      "{'loss': 0.4175, 'learning_rate': 6.341111495733474e-06, 'epoch': 0.84}         \n",
      "{'loss': 0.3227, 'learning_rate': 6.3209770093564315e-06, 'epoch': 0.84}        \n",
      "{'loss': 0.294, 'learning_rate': 6.300819468320988e-06, 'epoch': 0.84}          \n",
      "{'loss': 0.258, 'learning_rate': 6.280639224431317e-06, 'epoch': 0.85}          \n",
      "{'loss': 0.3284, 'learning_rate': 6.2604366298878184e-06, 'epoch': 0.85}        \n",
      "{'loss': 0.3772, 'learning_rate': 6.240212037280967e-06, 'epoch': 0.85}         \n",
      "{'loss': 0.3852, 'learning_rate': 6.219965799585172e-06, 'epoch': 0.85}         \n",
      "{'loss': 0.2578, 'learning_rate': 6.199698270152602e-06, 'epoch': 0.86}         \n",
      "{'loss': 0.2702, 'learning_rate': 6.179409802707026e-06, 'epoch': 0.86}         \n",
      "{'loss': 0.3105, 'learning_rate': 6.1591007513376425e-06, 'epoch': 0.86}        \n",
      "{'loss': 0.3603, 'learning_rate': 6.138771470492889e-06, 'epoch': 0.87}         \n",
      "{'loss': 0.2721, 'learning_rate': 6.118422314974269e-06, 'epoch': 0.87}         \n",
      "{'loss': 0.2775, 'learning_rate': 6.098053639930151e-06, 'epoch': 0.87}         \n",
      "{'loss': 0.2987, 'learning_rate': 6.077665800849568e-06, 'epoch': 0.87}         \n",
      "{'loss': 0.3143, 'learning_rate': 6.057259153556026e-06, 'epoch': 0.88}         \n",
      "{'loss': 0.3148, 'learning_rate': 6.036834054201283e-06, 'epoch': 0.88}         \n",
      "{'loss': 0.2665, 'learning_rate': 6.016390859259129e-06, 'epoch': 0.88}         \n",
      "{'loss': 0.3293, 'learning_rate': 5.995929925519181e-06, 'epoch': 0.88}         \n",
      "{'loss': 0.2936, 'learning_rate': 5.975451610080643e-06, 'epoch': 0.89}         \n",
      "{'loss': 0.2952, 'learning_rate': 5.954956270346074e-06, 'epoch': 0.89}         \n",
      "{'loss': 0.3934, 'learning_rate': 5.934444264015157e-06, 'epoch': 0.89}         \n",
      "{'loss': 0.2283, 'learning_rate': 5.913915949078453e-06, 'epoch': 0.89}         \n",
      "{'loss': 0.2956, 'learning_rate': 5.893371683811151e-06, 'epoch': 0.9}          \n",
      "{'loss': 0.2446, 'learning_rate': 5.872811826766817e-06, 'epoch': 0.9}          \n",
      "{'loss': 0.3064, 'learning_rate': 5.852236736771135e-06, 'epoch': 0.9}          \n",
      "{'loss': 0.3219, 'learning_rate': 5.831646772915651e-06, 'epoch': 0.9}          \n",
      "{'loss': 0.3681, 'learning_rate': 5.811042294551493e-06, 'epoch': 0.91}         \n",
      "{'loss': 0.2993, 'learning_rate': 5.790423661283112e-06, 'epoch': 0.91}         \n",
      "{'loss': 0.3628, 'learning_rate': 5.769791232962001e-06, 'epoch': 0.91}         \n",
      "{'loss': 0.3425, 'learning_rate': 5.7491453696804075e-06, 'epoch': 0.92}        \n",
      "{'loss': 0.2891, 'learning_rate': 5.728486431765067e-06, 'epoch': 0.92}         \n",
      "{'loss': 0.3801, 'learning_rate': 5.707814779770892e-06, 'epoch': 0.92}         \n",
      "{'loss': 0.4038, 'learning_rate': 5.687130774474697e-06, 'epoch': 0.92}         \n",
      "{'loss': 0.3631, 'learning_rate': 5.666434776868895e-06, 'epoch': 0.93}         \n",
      "{'loss': 0.3429, 'learning_rate': 5.645727148155195e-06, 'epoch': 0.93}         \n",
      "{'loss': 0.3213, 'learning_rate': 5.625008249738301e-06, 'epoch': 0.93}         \n",
      "{'loss': 0.3763, 'learning_rate': 5.604278443219608e-06, 'epoch': 0.93}         \n",
      "{'loss': 0.2544, 'learning_rate': 5.583538090390882e-06, 'epoch': 0.94}         \n",
      "{'loss': 0.2685, 'learning_rate': 5.562787553227953e-06, 'epoch': 0.94}         \n",
      "{'loss': 0.3259, 'learning_rate': 5.542027193884395e-06, 'epoch': 0.94}         \n",
      "{'loss': 0.3627, 'learning_rate': 5.5212573746852096e-06, 'epoch': 0.94}        \n",
      "{'loss': 0.2982, 'learning_rate': 5.500478458120493e-06, 'epoch': 0.95}         \n",
      "{'loss': 0.3903, 'learning_rate': 5.4796908068391176e-06, 'epoch': 0.95}        \n",
      "{'loss': 0.2932, 'learning_rate': 5.458894783642402e-06, 'epoch': 0.95}         \n",
      "{'loss': 0.3879, 'learning_rate': 5.438090751477777e-06, 'epoch': 0.95}         \n",
      "{'loss': 0.1886, 'learning_rate': 5.41727907343245e-06, 'epoch': 0.96}          \n",
      "{'loss': 0.299, 'learning_rate': 5.39646011272707e-06, 'epoch': 0.96}           \n",
      "{'loss': 0.3014, 'learning_rate': 5.375634232709392e-06, 'epoch': 0.96}         \n",
      "{'loss': 0.3583, 'learning_rate': 5.354801796847928e-06, 'epoch': 0.97}         \n",
      "{'loss': 0.2126, 'learning_rate': 5.3339631687256085e-06, 'epoch': 0.97}        \n",
      "{'loss': 0.2758, 'learning_rate': 5.313118712033436e-06, 'epoch': 0.97}         \n",
      "{'loss': 0.2539, 'learning_rate': 5.292268790564138e-06, 'epoch': 0.97}         \n",
      "{'loss': 0.2474, 'learning_rate': 5.271413768205816e-06, 'epoch': 0.98}         \n",
      "{'loss': 0.2938, 'learning_rate': 5.250554008935596e-06, 'epoch': 0.98}         \n",
      "{'loss': 0.2772, 'learning_rate': 5.229689876813281e-06, 'epoch': 0.98}         \n",
      "{'loss': 0.3401, 'learning_rate': 5.208821735974984e-06, 'epoch': 0.98}         \n",
      "{'loss': 0.3734, 'learning_rate': 5.187949950626786e-06, 'epoch': 0.99}         \n",
      "{'loss': 0.3771, 'learning_rate': 5.1670748850383734e-06, 'epoch': 0.99}        \n",
      "{'loss': 0.3171, 'learning_rate': 5.146196903536683e-06, 'epoch': 0.99}         \n",
      "{'loss': 0.3165, 'learning_rate': 5.1253163704995425e-06, 'epoch': 0.99}        \n",
      "{'loss': 0.2227, 'learning_rate': 5.104433650349307e-06, 'epoch': 1.0}          \n",
      "{'loss': 0.2858, 'learning_rate': 5.083549107546505e-06, 'epoch': 1.0}          \n",
      "{'loss': 0.3132, 'learning_rate': 5.06266310658348e-06, 'epoch': 1.0}           \n",
      "{'loss': 0.2535, 'learning_rate': 5.041776011978016e-06, 'epoch': 1.0}          \n",
      "{'loss': 0.2365, 'learning_rate': 5.0208881882669894e-06, 'epoch': 1.01}        \n",
      "{'loss': 0.3131, 'learning_rate': 5e-06, 'epoch': 1.01}                         \n",
      "{'loss': 0.2894, 'learning_rate': 4.979111811733013e-06, 'epoch': 1.01}         \n",
      "{'loss': 0.3046, 'learning_rate': 4.958223988021986e-06, 'epoch': 1.02}         \n",
      "{'loss': 0.3319, 'learning_rate': 4.937336893416521e-06, 'epoch': 1.02}         \n",
      "{'loss': 0.3786, 'learning_rate': 4.916450892453495e-06, 'epoch': 1.02}         \n",
      "{'loss': 0.317, 'learning_rate': 4.895566349650696e-06, 'epoch': 1.02}          \n",
      "{'loss': 0.3497, 'learning_rate': 4.87468362950046e-06, 'epoch': 1.03}          \n",
      "{'loss': 0.3628, 'learning_rate': 4.853803096463319e-06, 'epoch': 1.03}         \n",
      "{'loss': 0.3038, 'learning_rate': 4.832925114961629e-06, 'epoch': 1.03}         \n",
      "{'loss': 0.2415, 'learning_rate': 4.812050049373215e-06, 'epoch': 1.03}         \n",
      "{'loss': 0.3036, 'learning_rate': 4.791178264025017e-06, 'epoch': 1.04}         \n",
      "{'loss': 0.3266, 'learning_rate': 4.77031012318672e-06, 'epoch': 1.04}          \n",
      "{'loss': 0.3511, 'learning_rate': 4.7494459910644044e-06, 'epoch': 1.04}        \n",
      "{'loss': 0.2817, 'learning_rate': 4.728586231794185e-06, 'epoch': 1.04}         \n",
      "{'loss': 0.2874, 'learning_rate': 4.707731209435864e-06, 'epoch': 1.05}         \n",
      "{'loss': 0.2974, 'learning_rate': 4.686881287966565e-06, 'epoch': 1.05}         \n",
      "{'loss': 0.2828, 'learning_rate': 4.666036831274392e-06, 'epoch': 1.05}         \n",
      "{'loss': 0.2684, 'learning_rate': 4.6451982031520724e-06, 'epoch': 1.05}        \n",
      "{'loss': 0.2969, 'learning_rate': 4.624365767290609e-06, 'epoch': 1.06}         \n",
      "{'loss': 0.3226, 'learning_rate': 4.603539887272931e-06, 'epoch': 1.06}         \n",
      "{'loss': 0.2787, 'learning_rate': 4.582720926567552e-06, 'epoch': 1.06}         \n",
      "{'loss': 0.2407, 'learning_rate': 4.561909248522223e-06, 'epoch': 1.07}         \n",
      "{'loss': 0.304, 'learning_rate': 4.5411052163575986e-06, 'epoch': 1.07}         \n",
      "{'loss': 0.2999, 'learning_rate': 4.520309193160884e-06, 'epoch': 1.07}         \n",
      "{'loss': 0.2539, 'learning_rate': 4.499521541879508e-06, 'epoch': 1.07}         \n",
      "{'loss': 0.4091, 'learning_rate': 4.478742625314793e-06, 'epoch': 1.08}         \n",
      "{'loss': 0.3061, 'learning_rate': 4.457972806115607e-06, 'epoch': 1.08}         \n",
      "{'loss': 0.2544, 'learning_rate': 4.437212446772049e-06, 'epoch': 1.08}         \n",
      "{'loss': 0.2647, 'learning_rate': 4.416461909609119e-06, 'epoch': 1.08}         \n",
      "{'loss': 0.2541, 'learning_rate': 4.3957215567803934e-06, 'epoch': 1.09}        \n",
      "{'loss': 0.2718, 'learning_rate': 4.3749917502617e-06, 'epoch': 1.09}           \n",
      "{'loss': 0.2543, 'learning_rate': 4.354272851844807e-06, 'epoch': 1.09}         \n",
      "{'loss': 0.318, 'learning_rate': 4.333565223131107e-06, 'epoch': 1.09}          \n",
      "{'loss': 0.2616, 'learning_rate': 4.312869225525304e-06, 'epoch': 1.1}          \n",
      "{'loss': 0.3226, 'learning_rate': 4.29218522022911e-06, 'epoch': 1.1}           \n",
      "{'loss': 0.2655, 'learning_rate': 4.2715135682349345e-06, 'epoch': 1.1}         \n",
      "{'loss': 0.2597, 'learning_rate': 4.250854630319593e-06, 'epoch': 1.1}          \n",
      "{'loss': 0.2955, 'learning_rate': 4.230208767038002e-06, 'epoch': 1.11}         \n",
      "{'loss': 0.3316, 'learning_rate': 4.2095763387168895e-06, 'epoch': 1.11}        \n",
      "{'loss': 0.3058, 'learning_rate': 4.188957705448507e-06, 'epoch': 1.11}         \n",
      "{'loss': 0.3244, 'learning_rate': 4.1683532270843505e-06, 'epoch': 1.12}        \n",
      "{'loss': 0.3059, 'learning_rate': 4.147763263228866e-06, 'epoch': 1.12}         \n",
      "{'loss': 0.2059, 'learning_rate': 4.127188173233185e-06, 'epoch': 1.12}         \n",
      "{'loss': 0.2754, 'learning_rate': 4.1066283161888515e-06, 'epoch': 1.12}        \n",
      "{'loss': 0.2506, 'learning_rate': 4.08608405092155e-06, 'epoch': 1.13}          \n",
      "{'loss': 0.2954, 'learning_rate': 4.065555735984844e-06, 'epoch': 1.13}         \n",
      "{'loss': 0.3254, 'learning_rate': 4.045043729653927e-06, 'epoch': 1.13}         \n",
      "{'loss': 0.3083, 'learning_rate': 4.02454838991936e-06, 'epoch': 1.13}          \n",
      "{'loss': 0.297, 'learning_rate': 4.004070074480821e-06, 'epoch': 1.14}          \n",
      "{'loss': 0.272, 'learning_rate': 3.983609140740873e-06, 'epoch': 1.14}          \n",
      "{'loss': 0.3634, 'learning_rate': 3.963165945798718e-06, 'epoch': 1.14}         \n",
      "{'loss': 0.2646, 'learning_rate': 3.942740846443974e-06, 'epoch': 1.14}         \n",
      "{'loss': 0.259, 'learning_rate': 3.922334199150433e-06, 'epoch': 1.15}          \n",
      "{'loss': 0.3913, 'learning_rate': 3.901946360069851e-06, 'epoch': 1.15}         \n",
      "{'loss': 0.2966, 'learning_rate': 3.8815776850257325e-06, 'epoch': 1.15}        \n",
      "{'loss': 0.3304, 'learning_rate': 3.861228529507113e-06, 'epoch': 1.15}         \n",
      "{'loss': 0.2793, 'learning_rate': 3.840899248662358e-06, 'epoch': 1.16}         \n",
      "{'loss': 0.2939, 'learning_rate': 3.820590197292974e-06, 'epoch': 1.16}         \n",
      "{'loss': 0.2694, 'learning_rate': 3.8003017298474e-06, 'epoch': 1.16}           \n",
      "{'loss': 0.3204, 'learning_rate': 3.78003420041483e-06, 'epoch': 1.17}          \n",
      "{'loss': 0.2591, 'learning_rate': 3.7597879627190337e-06, 'epoch': 1.17}        \n",
      "{'loss': 0.2767, 'learning_rate': 3.739563370112185e-06, 'epoch': 1.17}         \n",
      "{'loss': 0.2343, 'learning_rate': 3.7193607755686836e-06, 'epoch': 1.17}        \n",
      "{'loss': 0.2601, 'learning_rate': 3.699180531679013e-06, 'epoch': 1.18}         \n",
      "{'loss': 0.3473, 'learning_rate': 3.6790229906435706e-06, 'epoch': 1.18}        \n",
      "{'loss': 0.2699, 'learning_rate': 3.6588885042665274e-06, 'epoch': 1.18}        \n",
      "{'loss': 0.2593, 'learning_rate': 3.6387774239496893e-06, 'epoch': 1.18}        \n",
      "{'loss': 0.3219, 'learning_rate': 3.6186901006863595e-06, 'epoch': 1.19}        \n",
      "{'loss': 0.3251, 'learning_rate': 3.598626885055219e-06, 'epoch': 1.19}         \n",
      "{'loss': 0.2913, 'learning_rate': 3.578588127214206e-06, 'epoch': 1.19}         \n",
      "{'loss': 0.2396, 'learning_rate': 3.5585741768943982e-06, 'epoch': 1.19}        \n",
      "{'loss': 0.2826, 'learning_rate': 3.5385853833939177e-06, 'epoch': 1.2}         \n",
      "{'loss': 0.3422, 'learning_rate': 3.518622095571831e-06, 'epoch': 1.2}          \n",
      "{'loss': 0.2812, 'learning_rate': 3.498684661842061e-06, 'epoch': 1.2}          \n",
      "{'loss': 0.3409, 'learning_rate': 3.478773430167302e-06, 'epoch': 1.2}          \n",
      "{'loss': 0.2194, 'learning_rate': 3.458888748052959e-06, 'epoch': 1.21}         \n",
      "{'loss': 0.3316, 'learning_rate': 3.439030962541069e-06, 'epoch': 1.21}         \n",
      "{'loss': 0.299, 'learning_rate': 3.41920042020425e-06, 'epoch': 1.21}           \n",
      "{'loss': 0.3172, 'learning_rate': 3.3993974671396523e-06, 'epoch': 1.22}        \n",
      "{'loss': 0.3566, 'learning_rate': 3.3796224489629205e-06, 'epoch': 1.22}        \n",
      "{'loss': 0.2479, 'learning_rate': 3.3598757108021546e-06, 'epoch': 1.22}        \n",
      "{'loss': 0.3158, 'learning_rate': 3.340157597291897e-06, 'epoch': 1.22}         \n",
      "{'loss': 0.3005, 'learning_rate': 3.320468452567106e-06, 'epoch': 1.23}         \n",
      "{'loss': 0.2875, 'learning_rate': 3.3008086202571598e-06, 'epoch': 1.23}        \n",
      "{'loss': 0.3681, 'learning_rate': 3.281178443479852e-06, 'epoch': 1.23}         \n",
      "{'loss': 0.2843, 'learning_rate': 3.2615782648354055e-06, 'epoch': 1.23}        \n",
      "{'loss': 0.3284, 'learning_rate': 3.2420084264004966e-06, 'epoch': 1.24}        \n",
      "{'loss': 0.2671, 'learning_rate': 3.2224692697222826e-06, 'epoch': 1.24}        \n",
      "{'loss': 0.3238, 'learning_rate': 3.202961135812437e-06, 'epoch': 1.24}         \n",
      "{'loss': 0.2648, 'learning_rate': 3.1834843651412017e-06, 'epoch': 1.24}        \n",
      "{'loss': 0.2413, 'learning_rate': 3.1640392976314472e-06, 'epoch': 1.25}        \n",
      "{'loss': 0.3092, 'learning_rate': 3.1446262726527354e-06, 'epoch': 1.25}        \n",
      "{'loss': 0.2088, 'learning_rate': 3.1252456290153952e-06, 'epoch': 1.25}        \n",
      "{'loss': 0.3827, 'learning_rate': 3.1058977049646192e-06, 'epoch': 1.25}        \n",
      "{'loss': 0.2497, 'learning_rate': 3.0865828381745515e-06, 'epoch': 1.26}        \n",
      "{'loss': 0.3341, 'learning_rate': 3.0673013657423943e-06, 'epoch': 1.26}        \n",
      "{'loss': 0.2902, 'learning_rate': 3.0480536241825263e-06, 'epoch': 1.26}        \n",
      "{'loss': 0.3749, 'learning_rate': 3.0288399494206345e-06, 'epoch': 1.27}        \n",
      "{'loss': 0.1906, 'learning_rate': 3.009660676787846e-06, 'epoch': 1.27}         \n",
      "{'loss': 0.3238, 'learning_rate': 2.990516141014875e-06, 'epoch': 1.27}         \n",
      "{'loss': 0.3366, 'learning_rate': 2.9714066762261825e-06, 'epoch': 1.27}        \n",
      "{'loss': 0.2658, 'learning_rate': 2.952332615934147e-06, 'epoch': 1.28}         \n",
      "{'loss': 0.3023, 'learning_rate': 2.9332942930332404e-06, 'epoch': 1.28}        \n",
      "{'loss': 0.3336, 'learning_rate': 2.9142920397942177e-06, 'epoch': 1.28}        \n",
      "{'loss': 0.1659, 'learning_rate': 2.8953261878583263e-06, 'epoch': 1.28}        \n",
      "{'loss': 0.2799, 'learning_rate': 2.8763970682315035e-06, 'epoch': 1.29}        \n",
      "{'loss': 0.2617, 'learning_rate': 2.85750501127861e-06, 'epoch': 1.29}          \n",
      "{'loss': 0.278, 'learning_rate': 2.838650346717666e-06, 'epoch': 1.29}          \n",
      "{'loss': 0.3016, 'learning_rate': 2.8198334036140873e-06, 'epoch': 1.29}        \n",
      "{'loss': 0.2315, 'learning_rate': 2.8010545103749464e-06, 'epoch': 1.3}         \n",
      "{'loss': 0.2976, 'learning_rate': 2.782313994743247e-06, 'epoch': 1.3}          \n",
      "{'loss': 0.2764, 'learning_rate': 2.7636121837921947e-06, 'epoch': 1.3}         \n",
      "{'loss': 0.3101, 'learning_rate': 2.74494940391949e-06, 'epoch': 1.3}           \n",
      "{'loss': 0.3116, 'learning_rate': 2.7263259808416444e-06, 'epoch': 1.31}        \n",
      "{'loss': 0.2838, 'learning_rate': 2.7077422395882745e-06, 'epoch': 1.31}        \n",
      "{'loss': 0.2516, 'learning_rate': 2.6891985044964465e-06, 'epoch': 1.31}        \n",
      "{'loss': 0.288, 'learning_rate': 2.6706950992050097e-06, 'epoch': 1.32}         \n",
      "{'loss': 0.3075, 'learning_rate': 2.6522323466489475e-06, 'epoch': 1.32}        \n",
      "{'loss': 0.2758, 'learning_rate': 2.6338105690537402e-06, 'epoch': 1.32}        \n",
      "{'loss': 0.2775, 'learning_rate': 2.6154300879297436e-06, 'epoch': 1.32}        \n",
      "{'loss': 0.2596, 'learning_rate': 2.5970912240665815e-06, 'epoch': 1.33}        \n",
      "{'loss': 0.2962, 'learning_rate': 2.5787942975275365e-06, 'epoch': 1.33}        \n",
      "{'loss': 0.2658, 'learning_rate': 2.5605396276439764e-06, 'epoch': 1.33}        \n",
      "{'loss': 0.2074, 'learning_rate': 2.5423275330097697e-06, 'epoch': 1.33}        \n",
      "{'loss': 0.2969, 'learning_rate': 2.5241583314757327e-06, 'epoch': 1.34}        \n",
      "{'loss': 0.2749, 'learning_rate': 2.50603234014408e-06, 'epoch': 1.34}          \n",
      "{'loss': 0.2138, 'learning_rate': 2.4879498753628885e-06, 'epoch': 1.34}        \n",
      "{'loss': 0.2616, 'learning_rate': 2.4699112527205815e-06, 'epoch': 1.34}        \n",
      "{'loss': 0.2603, 'learning_rate': 2.4519167870404126e-06, 'epoch': 1.35}        \n",
      "{'loss': 0.2763, 'learning_rate': 2.4339667923749804e-06, 'epoch': 1.35}        \n",
      "{'loss': 0.255, 'learning_rate': 2.41606158200074e-06, 'epoch': 1.35}           \n",
      "{'loss': 0.2862, 'learning_rate': 2.3982014684125372e-06, 'epoch': 1.35}        \n",
      "{'loss': 0.2678, 'learning_rate': 2.3803867633181575e-06, 'epoch': 1.36}        \n",
      "{'loss': 0.2872, 'learning_rate': 2.3626177776328827e-06, 'epoch': 1.36}        \n",
      "{'loss': 0.2717, 'learning_rate': 2.3448948214740703e-06, 'epoch': 1.36}        \n",
      "{'loss': 0.2832, 'learning_rate': 2.327218204155729e-06, 'epoch': 1.37}         \n",
      "{'loss': 0.2728, 'learning_rate': 2.309588234183137e-06, 'epoch': 1.37}         \n",
      "{'loss': 0.3296, 'learning_rate': 2.2920052192474423e-06, 'epoch': 1.37}        \n",
      "{'loss': 0.2666, 'learning_rate': 2.2744694662203022e-06, 'epoch': 1.37}        \n",
      "{'loss': 0.3529, 'learning_rate': 2.2569812811485204e-06, 'epoch': 1.38}        \n",
      "{'loss': 0.3188, 'learning_rate': 2.2395409692487174e-06, 'epoch': 1.38}        \n",
      "{'loss': 0.2967, 'learning_rate': 2.2221488349019903e-06, 'epoch': 1.38}        \n",
      "{'loss': 0.2742, 'learning_rate': 2.2048051816486054e-06, 'epoch': 1.38}        \n",
      "{'loss': 0.2803, 'learning_rate': 2.1875103121827075e-06, 'epoch': 1.39}        \n",
      "{'loss': 0.2675, 'learning_rate': 2.1702645283470238e-06, 'epoch': 1.39}        \n",
      "{'loss': 0.2649, 'learning_rate': 2.1530681311276096e-06, 'epoch': 1.39}        \n",
      "{'loss': 0.2779, 'learning_rate': 2.1359214206485845e-06, 'epoch': 1.39}        \n",
      "{'loss': 0.3421, 'learning_rate': 2.1188246961668995e-06, 'epoch': 1.4}         \n",
      "{'loss': 0.3553, 'learning_rate': 2.1017782560671124e-06, 'epoch': 1.4}         \n",
      "{'loss': 0.3358, 'learning_rate': 2.0847823978561863e-06, 'epoch': 1.4}         \n",
      "{'loss': 0.2796, 'learning_rate': 2.0678374181582845e-06, 'epoch': 1.4}         \n",
      "{'loss': 0.2834, 'learning_rate': 2.050943612709608e-06, 'epoch': 1.41}         \n",
      "{'loss': 0.2689, 'learning_rate': 2.0341012763532243e-06, 'epoch': 1.41}        \n",
      "{'loss': 0.3042, 'learning_rate': 2.0173107030339234e-06, 'epoch': 1.41}        \n",
      "{'loss': 0.235, 'learning_rate': 2.0005721857930902e-06, 'epoch': 1.42}         \n",
      "{'loss': 0.4017, 'learning_rate': 1.9838860167635878e-06, 'epoch': 1.42}        \n",
      "{'loss': 0.3114, 'learning_rate': 1.967252487164663e-06, 'epoch': 1.42}         \n",
      "{'loss': 0.2774, 'learning_rate': 1.950671887296857e-06, 'epoch': 1.42}         \n",
      "{'loss': 0.262, 'learning_rate': 1.934144506536946e-06, 'epoch': 1.43}          \n",
      "{'loss': 0.2929, 'learning_rate': 1.9176706333328856e-06, 'epoch': 1.43}        \n",
      "{'loss': 0.3359, 'learning_rate': 1.9012505551987764e-06, 'epoch': 1.43}        \n",
      "{'loss': 0.2232, 'learning_rate': 1.8848845587098513e-06, 'epoch': 1.43}        \n",
      "{'loss': 0.2086, 'learning_rate': 1.8685729294974668e-06, 'epoch': 1.44}        \n",
      "{'loss': 0.2648, 'learning_rate': 1.8523159522441281e-06, 'epoch': 1.44}        \n",
      "{'loss': 0.2927, 'learning_rate': 1.836113910678507e-06, 'epoch': 1.44}         \n",
      "{'loss': 0.3212, 'learning_rate': 1.819967087570505e-06, 'epoch': 1.44}         \n",
      "{'loss': 0.2913, 'learning_rate': 1.8038757647263045e-06, 'epoch': 1.45}        \n",
      "{'loss': 0.2835, 'learning_rate': 1.787840222983459e-06, 'epoch': 1.45}         \n",
      "{'loss': 0.2561, 'learning_rate': 1.771860742205988e-06, 'epoch': 1.45}         \n",
      "{'loss': 0.3073, 'learning_rate': 1.7559376012794981e-06, 'epoch': 1.45}        \n",
      "{'loss': 0.3089, 'learning_rate': 1.7400710781063073e-06, 'epoch': 1.46}        \n",
      "{'loss': 0.3579, 'learning_rate': 1.7242614496005988e-06, 'epoch': 1.46}        \n",
      "{'loss': 0.285, 'learning_rate': 1.7085089916835924e-06, 'epoch': 1.46}         \n",
      "{'loss': 0.301, 'learning_rate': 1.6928139792787224e-06, 'epoch': 1.47}         \n",
      "{'loss': 0.2564, 'learning_rate': 1.6771766863068389e-06, 'epoch': 1.47}        \n",
      "{'loss': 0.2858, 'learning_rate': 1.6615973856814376e-06, 'epoch': 1.47}        \n",
      "{'loss': 0.277, 'learning_rate': 1.646076349303884e-06, 'epoch': 1.47}          \n",
      "{'loss': 0.3318, 'learning_rate': 1.6306138480586707e-06, 'epoch': 1.48}        \n",
      "{'loss': 0.2343, 'learning_rate': 1.615210151808701e-06, 'epoch': 1.48}         \n",
      "{'loss': 0.3479, 'learning_rate': 1.5998655293905634e-06, 'epoch': 1.48}        \n",
      "{'loss': 0.241, 'learning_rate': 1.5845802486098461e-06, 'epoch': 1.48}         \n",
      "{'loss': 0.2962, 'learning_rate': 1.5693545762364693e-06, 'epoch': 1.49}        \n",
      "{'loss': 0.3371, 'learning_rate': 1.5541887780000187e-06, 'epoch': 1.49}        \n",
      "{'loss': 0.2763, 'learning_rate': 1.5390831185851147e-06, 'epoch': 1.49}        \n",
      "{'loss': 0.2781, 'learning_rate': 1.5240378616267887e-06, 'epoch': 1.49}        \n",
      "{'loss': 0.3743, 'learning_rate': 1.509053269705889e-06, 'epoch': 1.5}          \n",
      "{'loss': 0.3208, 'learning_rate': 1.4941296043444869e-06, 'epoch': 1.5}         \n",
      "{'loss': 0.2989, 'learning_rate': 1.4792671260013258e-06, 'epoch': 1.5}         \n",
      "{'loss': 0.2954, 'learning_rate': 1.4644660940672628e-06, 'epoch': 1.5}         \n",
      "{'loss': 0.207, 'learning_rate': 1.449726766860749e-06, 'epoch': 1.51}          \n",
      "{'loss': 0.2581, 'learning_rate': 1.4350494016233197e-06, 'epoch': 1.51}        \n",
      "{'loss': 0.2346, 'learning_rate': 1.4204342545151023e-06, 'epoch': 1.51}        \n",
      "{'loss': 0.2064, 'learning_rate': 1.4058815806103542e-06, 'epoch': 1.52}        \n",
      "{'loss': 0.3309, 'learning_rate': 1.391391633892996e-06, 'epoch': 1.52}         \n",
      "{'loss': 0.235, 'learning_rate': 1.3769646672521964e-06, 'epoch': 1.52}         \n",
      "{'loss': 0.2496, 'learning_rate': 1.362600932477942e-06, 'epoch': 1.52}         \n",
      "{'loss': 0.2748, 'learning_rate': 1.3483006802566546e-06, 'epoch': 1.53}        \n",
      "{'loss': 0.2977, 'learning_rate': 1.3340641601668097e-06, 'epoch': 1.53}        \n",
      "{'loss': 0.2806, 'learning_rate': 1.3198916206745871e-06, 'epoch': 1.53}        \n",
      "{'loss': 0.2403, 'learning_rate': 1.3057833091295257e-06, 'epoch': 1.53}        \n",
      "{'loss': 0.2697, 'learning_rate': 1.2917394717602123e-06, 'epoch': 1.54}        \n",
      "{'loss': 0.2636, 'learning_rate': 1.2777603536699867e-06, 'epoch': 1.54}        \n",
      "{'loss': 0.3326, 'learning_rate': 1.2638461988326556e-06, 'epoch': 1.54}        \n",
      "{'loss': 0.2909, 'learning_rate': 1.2499972500882412e-06, 'epoch': 1.54}        \n",
      "{'loss': 0.3285, 'learning_rate': 1.2362137491387433e-06, 'epoch': 1.55}        \n",
      "{'loss': 0.2879, 'learning_rate': 1.2224959365439165e-06, 'epoch': 1.55}        \n",
      "{'loss': 0.3465, 'learning_rate': 1.2088440517170729e-06, 'epoch': 1.55}        \n",
      "{'loss': 0.2472, 'learning_rate': 1.1952583329209095e-06, 'epoch': 1.55}        \n",
      "{'loss': 0.2431, 'learning_rate': 1.1817390172633402e-06, 'epoch': 1.56}        \n",
      "{'loss': 0.2698, 'learning_rate': 1.1682863406933654e-06, 'epoch': 1.56}        \n",
      "{'loss': 0.2748, 'learning_rate': 1.154900537996952e-06, 'epoch': 1.56}         \n",
      "{'loss': 0.2288, 'learning_rate': 1.1415818427929332e-06, 'epoch': 1.57}        \n",
      "{'loss': 0.2338, 'learning_rate': 1.1283304875289335e-06, 'epoch': 1.57}        \n",
      "{'loss': 0.3013, 'learning_rate': 1.1151467034773111e-06, 'epoch': 1.57}        \n",
      "{'loss': 0.2622, 'learning_rate': 1.1020307207311244e-06, 'epoch': 1.57}        \n",
      "{'loss': 0.21, 'learning_rate': 1.0889827682001097e-06, 'epoch': 1.58}          \n",
      "{'loss': 0.3442, 'learning_rate': 1.0760030736066952e-06, 'epoch': 1.58}        \n",
      "{'loss': 0.2694, 'learning_rate': 1.063091863482017e-06, 'epoch': 1.58}         \n",
      "{'loss': 0.285, 'learning_rate': 1.0502493631619715e-06, 'epoch': 1.58}         \n",
      "{'loss': 0.2029, 'learning_rate': 1.0374757967832826e-06, 'epoch': 1.59}        \n",
      "{'loss': 0.2761, 'learning_rate': 1.024771387279585e-06, 'epoch': 1.59}         \n",
      "{'loss': 0.3695, 'learning_rate': 1.0121363563775433e-06, 'epoch': 1.59}        \n",
      "{'loss': 0.2759, 'learning_rate': 9.995709245929691e-07, 'epoch': 1.59}         \n",
      "{'loss': 0.2737, 'learning_rate': 9.870753112269842e-07, 'epoch': 1.6}          \n",
      "{'loss': 0.3079, 'learning_rate': 9.746497343621857e-07, 'epoch': 1.6}          \n",
      "{'loss': 0.2885, 'learning_rate': 9.622944108588428e-07, 'epoch': 1.6}          \n",
      "{'loss': 0.329, 'learning_rate': 9.500095563511119e-07, 'epoch': 1.6}           \n",
      "{'loss': 0.2726, 'learning_rate': 9.377953852432709e-07, 'epoch': 1.61}         \n",
      "{'loss': 0.257, 'learning_rate': 9.256521107059834e-07, 'epoch': 1.61}          \n",
      "{'loss': 0.2427, 'learning_rate': 9.135799446725701e-07, 'epoch': 1.61}         \n",
      "{'loss': 0.3831, 'learning_rate': 9.015790978353173e-07, 'epoch': 1.62}         \n",
      "{'loss': 0.2929, 'learning_rate': 8.896497796417941e-07, 'epoch': 1.62}         \n",
      "{'loss': 0.268, 'learning_rate': 8.777921982911996e-07, 'epoch': 1.62}          \n",
      "{'loss': 0.2658, 'learning_rate': 8.660065607307283e-07, 'epoch': 1.62}         \n",
      "{'loss': 0.2857, 'learning_rate': 8.542930726519622e-07, 'epoch': 1.63}         \n",
      "{'loss': 0.3063, 'learning_rate': 8.426519384872733e-07, 'epoch': 1.63}         \n",
      "{'loss': 0.3218, 'learning_rate': 8.310833614062652e-07, 'epoch': 1.63}         \n",
      "{'loss': 0.214, 'learning_rate': 8.195875433122175e-07, 'epoch': 1.63}          \n",
      "{'loss': 0.2889, 'learning_rate': 8.081646848385671e-07, 'epoch': 1.64}         \n",
      "{'loss': 0.298, 'learning_rate': 7.968149853454105e-07, 'epoch': 1.64}          \n",
      "{'loss': 0.2846, 'learning_rate': 7.85538642916015e-07, 'epoch': 1.64}          \n",
      "{'loss': 0.1831, 'learning_rate': 7.743358543533696e-07, 'epoch': 1.64}         \n",
      "{'loss': 0.2639, 'learning_rate': 7.632068151767447e-07, 'epoch': 1.65}         \n",
      "{'loss': 0.3904, 'learning_rate': 7.521517196182865e-07, 'epoch': 1.65}         \n",
      "{'loss': 0.3597, 'learning_rate': 7.411707606196189e-07, 'epoch': 1.65}         \n",
      "{'loss': 0.2885, 'learning_rate': 7.302641298284835e-07, 'epoch': 1.65}         \n",
      "{'loss': 0.3044, 'learning_rate': 7.194320175953901e-07, 'epoch': 1.66}         \n",
      "{'loss': 0.3206, 'learning_rate': 7.086746129702948e-07, 'epoch': 1.66}         \n",
      "{'loss': 0.2521, 'learning_rate': 6.979921036993042e-07, 'epoch': 1.66}         \n",
      "{'loss': 0.3156, 'learning_rate': 6.873846762213931e-07, 'epoch': 1.67}         \n",
      "{'loss': 0.3015, 'learning_rate': 6.768525156651589e-07, 'epoch': 1.67}         \n",
      "{'loss': 0.3065, 'learning_rate': 6.6639580584558e-07, 'epoch': 1.67}           \n",
      "{'loss': 0.2635, 'learning_rate': 6.560147292608177e-07, 'epoch': 1.67}         \n",
      "{'loss': 0.303, 'learning_rate': 6.457094670890241e-07, 'epoch': 1.68}          \n",
      "{'loss': 0.2813, 'learning_rate': 6.354801991851839e-07, 'epoch': 1.68}         \n",
      "{'loss': 0.2679, 'learning_rate': 6.253271040779724e-07, 'epoch': 1.68}         \n",
      "{'loss': 0.2612, 'learning_rate': 6.152503589666426e-07, 'epoch': 1.68}         \n",
      "{'loss': 0.3685, 'learning_rate': 6.052501397179333e-07, 'epoch': 1.69}         \n",
      "{'loss': 0.3217, 'learning_rate': 5.953266208629943e-07, 'epoch': 1.69}         \n",
      "{'loss': 0.3052, 'learning_rate': 5.854799755943474e-07, 'epoch': 1.69}         \n",
      "{'loss': 0.3006, 'learning_rate': 5.757103757628573e-07, 'epoch': 1.69}         \n",
      "{'loss': 0.22, 'learning_rate': 5.660179918747377e-07, 'epoch': 1.7}            \n",
      "{'loss': 0.2975, 'learning_rate': 5.5640299308857e-07, 'epoch': 1.7}            \n",
      "{'loss': 0.2584, 'learning_rate': 5.468655472123591e-07, 'epoch': 1.7}          \n",
      "{'loss': 0.248, 'learning_rate': 5.374058207005945e-07, 'epoch': 1.7}           \n",
      "{'loss': 0.3705, 'learning_rate': 5.280239786513525e-07, 'epoch': 1.71}         \n",
      "{'loss': 0.3003, 'learning_rate': 5.187201848034146e-07, 'epoch': 1.71}         \n",
      "{'loss': 0.3111, 'learning_rate': 5.094946015334057e-07, 'epoch': 1.71}         \n",
      "{'loss': 0.2705, 'learning_rate': 5.00347389852961e-07, 'epoch': 1.72}          \n",
      "{'loss': 0.2671, 'learning_rate': 4.912787094059218e-07, 'epoch': 1.72}         \n",
      "{'loss': 0.2784, 'learning_rate': 4.822887184655406e-07, 'epoch': 1.72}         \n",
      "{'loss': 0.3261, 'learning_rate': 4.7337757393172423e-07, 'epoch': 1.72}        \n",
      "{'loss': 0.2662, 'learning_rate': 4.6454543132829653e-07, 'epoch': 1.73}        \n",
      "{'loss': 0.3385, 'learning_rate': 4.5579244480027875e-07, 'epoch': 1.73}        \n",
      "{'loss': 0.2806, 'learning_rate': 4.4711876711120206e-07, 'epoch': 1.73}        \n",
      "{'loss': 0.2741, 'learning_rate': 4.3852454964044555e-07, 'epoch': 1.73}        \n",
      "{'loss': 0.2182, 'learning_rate': 4.300099423805865e-07, 'epoch': 1.74}         \n",
      "{'loss': 0.2269, 'learning_rate': 4.2157509393478845e-07, 'epoch': 1.74}        \n",
      "{'loss': 0.2177, 'learning_rate': 4.132201515142037e-07, 'epoch': 1.74}         \n",
      "{'loss': 0.2857, 'learning_rate': 4.049452609354093e-07, 'epoch': 1.74}         \n",
      "{'loss': 0.3774, 'learning_rate': 3.9675056661785563e-07, 'epoch': 1.75}        \n",
      "{'loss': 0.3027, 'learning_rate': 3.8863621158135247e-07, 'epoch': 1.75}        \n",
      "{'loss': 0.2961, 'learning_rate': 3.8060233744356634e-07, 'epoch': 1.75}        \n",
      "{'loss': 0.3394, 'learning_rate': 3.72649084417554e-07, 'epoch': 1.75}          \n",
      "{'loss': 0.2916, 'learning_rate': 3.647765913093132e-07, 'epoch': 1.76}         \n",
      "{'loss': 0.2468, 'learning_rate': 3.569849955153593e-07, 'epoch': 1.76}         \n",
      "{'loss': 0.3536, 'learning_rate': 3.4927443302033127e-07, 'epoch': 1.76}        \n",
      "{'loss': 0.2709, 'learning_rate': 3.4164503839461184e-07, 'epoch': 1.77}        \n",
      "{'loss': 0.2468, 'learning_rate': 3.340969447919873e-07, 'epoch': 1.77}         \n",
      "{'loss': 0.2389, 'learning_rate': 3.2663028394731453e-07, 'epoch': 1.77}        \n",
      "{'loss': 0.3064, 'learning_rate': 3.1924518617422796e-07, 'epoch': 1.77}        \n",
      "{'loss': 0.2595, 'learning_rate': 3.119417803628638e-07, 'epoch': 1.78}         \n",
      "{'loss': 0.3811, 'learning_rate': 3.0472019397761065e-07, 'epoch': 1.78}        \n",
      "{'loss': 0.3225, 'learning_rate': 2.9758055305488365e-07, 'epoch': 1.78}        \n",
      "{'loss': 0.2766, 'learning_rate': 2.905229822009253e-07, 'epoch': 1.78}         \n",
      "{'loss': 0.2796, 'learning_rate': 2.8354760458963293e-07, 'epoch': 1.79}        \n",
      "{'loss': 0.2619, 'learning_rate': 2.7665454196040665e-07, 'epoch': 1.79}        \n",
      "{'loss': 0.331, 'learning_rate': 2.6984391461602255e-07, 'epoch': 1.79}         \n",
      "{'loss': 0.3781, 'learning_rate': 2.6311584142054036e-07, 'epoch': 1.79}        \n",
      "{'loss': 0.3905, 'learning_rate': 2.5647043979722066e-07, 'epoch': 1.8}         \n",
      "{'loss': 0.304, 'learning_rate': 2.4990782572647977e-07, 'epoch': 1.8}          \n",
      "{'loss': 0.2664, 'learning_rate': 2.4342811374386766e-07, 'epoch': 1.8}         \n",
      "{'loss': 0.3338, 'learning_rate': 2.3703141693806276e-07, 'epoch': 1.8}         \n",
      "{'loss': 0.2595, 'learning_rate': 2.30717846948903e-07, 'epoch': 1.81}          \n",
      "{'loss': 0.3007, 'learning_rate': 2.2448751396543788e-07, 'epoch': 1.81}        \n",
      "{'loss': 0.3072, 'learning_rate': 2.1834052672400185e-07, 'epoch': 1.81}        \n",
      "{'loss': 0.3313, 'learning_rate': 2.122769925063195e-07, 'epoch': 1.82}         \n",
      "{'loss': 0.2641, 'learning_rate': 2.062970171376305e-07, 'epoch': 1.82}         \n",
      "{'loss': 0.2501, 'learning_rate': 2.004007049848461e-07, 'epoch': 1.82}         \n",
      "{'loss': 0.3188, 'learning_rate': 1.9458815895472494e-07, 'epoch': 1.82}        \n",
      "{'loss': 0.2468, 'learning_rate': 1.8885948049207847e-07, 'epoch': 1.83}        \n",
      "{'loss': 0.2853, 'learning_rate': 1.8321476957799956e-07, 'epoch': 1.83}        \n",
      "{'loss': 0.3355, 'learning_rate': 1.776541247281177e-07, 'epoch': 1.83}         \n",
      "{'loss': 0.2842, 'learning_rate': 1.7217764299087946e-07, 'epoch': 1.83}        \n",
      "{'loss': 0.3096, 'learning_rate': 1.6678541994585629e-07, 'epoch': 1.84}        \n",
      "{'loss': 0.2355, 'learning_rate': 1.6147754970207484e-07, 'epoch': 1.84}        \n",
      "{'loss': 0.3965, 'learning_rate': 1.5625412489637337e-07, 'epoch': 1.84}        \n",
      "{'loss': 0.2551, 'learning_rate': 1.5111523669179007e-07, 'epoch': 1.84}        \n",
      "{'loss': 0.3041, 'learning_rate': 1.4606097477596504e-07, 'epoch': 1.85}        \n",
      "{'loss': 0.3057, 'learning_rate': 1.4109142735957927e-07, 'epoch': 1.85}        \n",
      "{'loss': 0.324, 'learning_rate': 1.3620668117481471e-07, 'epoch': 1.85}         \n",
      "{'loss': 0.2902, 'learning_rate': 1.3140682147383954e-07, 'epoch': 1.85}        \n",
      "{'loss': 0.2662, 'learning_rate': 1.266919320273219e-07, 'epoch': 1.86}         \n",
      "{'loss': 0.2737, 'learning_rate': 1.2206209512296562e-07, 'epoch': 1.86}        \n",
      "{'loss': 0.2738, 'learning_rate': 1.1751739156407649e-07, 'epoch': 1.86}        \n",
      "{'loss': 0.3488, 'learning_rate': 1.130579006681498e-07, 'epoch': 1.87}         \n",
      "{'loss': 0.3534, 'learning_rate': 1.086837002654867e-07, 'epoch': 1.87}         \n",
      "{'loss': 0.2374, 'learning_rate': 1.0439486669783672e-07, 'epoch': 1.87}        \n",
      "{'loss': 0.3318, 'learning_rate': 1.0019147481706626e-07, 'epoch': 1.87}        \n",
      "{'loss': 0.302, 'learning_rate': 9.607359798384785e-08, 'epoch': 1.88}          \n",
      "{'loss': 0.319, 'learning_rate': 9.204130806638511e-08, 'epoch': 1.88}          \n",
      "{'loss': 0.3204, 'learning_rate': 8.809467543915595e-08, 'epoch': 1.88}         \n",
      "{'loss': 0.3271, 'learning_rate': 8.423376898168246e-08, 'epoch': 1.88}         \n",
      "{'loss': 0.2608, 'learning_rate': 8.045865607733406e-08, 'epoch': 1.89}         \n",
      "{'loss': 0.2941, 'learning_rate': 7.676940261214516e-08, 'epoch': 1.89}         \n",
      "{'loss': 0.2871, 'learning_rate': 7.31660729736705e-08, 'epoch': 1.89}          \n",
      "{'loss': 0.2644, 'learning_rate': 6.964873004985717e-08, 'epoch': 1.89}         \n",
      "{'loss': 0.2542, 'learning_rate': 6.62174352279521e-08, 'epoch': 1.9}           \n",
      "{'loss': 0.2128, 'learning_rate': 6.28722483934241e-08, 'epoch': 1.9}           \n",
      "{'loss': 0.3239, 'learning_rate': 5.961322792892632e-08, 'epoch': 1.9}          \n",
      "{'loss': 0.2911, 'learning_rate': 5.6440430713269325e-08, 'epoch': 1.9}         \n",
      "{'loss': 0.3149, 'learning_rate': 5.335391212043517e-08, 'epoch': 1.91}         \n",
      "{'loss': 0.2755, 'learning_rate': 5.035372601860766e-08, 'epoch': 1.91}         \n",
      "{'loss': 0.2231, 'learning_rate': 4.743992476923087e-08, 'epoch': 1.91}         \n",
      "{'loss': 0.2331, 'learning_rate': 4.461255922609986e-08, 'epoch': 1.92}         \n",
      "{'loss': 0.3141, 'learning_rate': 4.187167873446807e-08, 'epoch': 1.92}         \n",
      "{'loss': 0.3745, 'learning_rate': 3.921733113019077e-08, 'epoch': 1.92}         \n",
      "{'loss': 0.2525, 'learning_rate': 3.6649562738886315e-08, 'epoch': 1.92}        \n",
      "{'loss': 0.2803, 'learning_rate': 3.416841837512952e-08, 'epoch': 1.93}         \n",
      "{'loss': 0.3164, 'learning_rate': 3.1773941341669e-08, 'epoch': 1.93}           \n",
      "{'loss': 0.3078, 'learning_rate': 2.9466173428672197e-08, 'epoch': 1.93}        \n",
      "{'loss': 0.2754, 'learning_rate': 2.7245154912994844e-08, 'epoch': 1.93}        \n",
      "{'loss': 0.3054, 'learning_rate': 2.511092455747932e-08, 'epoch': 1.94}         \n",
      "{'loss': 0.3223, 'learning_rate': 2.3063519610277974e-08, 'epoch': 1.94}        \n",
      "{'loss': 0.3486, 'learning_rate': 2.1102975804200287e-08, 'epoch': 1.94}        \n",
      "{'loss': 0.2472, 'learning_rate': 1.9229327356093397e-08, 'epoch': 1.94}        \n",
      "{'loss': 0.2543, 'learning_rate': 1.7442606966242005e-08, 'epoch': 1.95}        \n",
      "{'loss': 0.2152, 'learning_rate': 1.57428458178005e-08, 'epoch': 1.95}          \n",
      "{'loss': 0.2506, 'learning_rate': 1.4130073576244518e-08, 'epoch': 1.95}        \n",
      "{'loss': 0.3018, 'learning_rate': 1.260431838885634e-08, 'epoch': 1.95}         \n",
      "{'loss': 0.2624, 'learning_rate': 1.1165606884234182e-08, 'epoch': 1.96}        \n",
      "{'loss': 0.3444, 'learning_rate': 9.813964171824231e-09, 'epoch': 1.96}         \n",
      "{'loss': 0.3523, 'learning_rate': 8.549413841485443e-09, 'epoch': 1.96}         \n",
      "{'loss': 0.2449, 'learning_rate': 7.371977963077093e-09, 'epoch': 1.97}         \n",
      "{'loss': 0.3226, 'learning_rate': 6.281677086071303e-09, 'epoch': 1.97}         \n",
      "{'loss': 0.258, 'learning_rate': 5.278530239198332e-09, 'epoch': 1.97}          \n",
      "{'loss': 0.3056, 'learning_rate': 4.362554930112395e-09, 'epoch': 1.97}         \n",
      "{'loss': 0.2893, 'learning_rate': 3.533767145084688e-09, 'epoch': 1.98}         \n",
      "{'loss': 0.355, 'learning_rate': 2.792181348726941e-09, 'epoch': 1.98}          \n",
      "{'loss': 0.2791, 'learning_rate': 2.1378104837377345e-09, 'epoch': 1.98}        \n",
      "{'loss': 0.3113, 'learning_rate': 1.5706659706771211e-09, 'epoch': 1.98}        \n",
      "{'loss': 0.3218, 'learning_rate': 1.0907577077656772e-09, 'epoch': 1.99}        \n",
      "{'loss': 0.2989, 'learning_rate': 6.980940707146388e-10, 'epoch': 1.99}         \n",
      "{'loss': 0.3152, 'learning_rate': 3.9268191257768593e-10, 'epoch': 1.99}        \n",
      "{'loss': 0.351, 'learning_rate': 1.7452656363103893e-10, 'epoch': 1.99}         \n",
      "{'loss': 0.2985, 'learning_rate': 4.3631831281309986e-11, 'epoch': 2.0}         \n",
      "{'loss': 0.2577, 'learning_rate': 0.0, 'epoch': 2.0}                            \n",
      "{'train_runtime': 31586.8335, 'train_samples_per_second': 0.193, 'train_steps_per_second': 0.024, 'train_loss': 0.45934101194143295, 'epoch': 2.0}\n",
      "100%|███████████████████████████████████████| 760/760 [8:46:26<00:00, 41.56s/it]\n"
     ]
    }
   ],
   "source": [
    "!sh /hpc2hdd/home/yliu364/Qwen-VL/finetune/finetune_lora_single_gpu.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    \"/hpc2hdd/home/yliu364/Qwen-VL/output_qwen_chat/checkpoint-300\", # path to the output directory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ref> Search icon</ref><box>(13,103),(100,153)</box>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/hpc2hdd/home/yliu364/Qwen-VL/output_qwen_chat/checkpoint-300\", trust_remote_code=True)\n",
    "image_path = '/hpc2hdd/home/yliu364/2.jpg'\n",
    "response, history = model.chat(tokenizer, query=f'<img>{image_path}</img>Please give me the coordinates of Search icon', history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
    "if image:\n",
    "  image.save('2.jpg')\n",
    "else:\n",
    "  print(\"no box\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a38706d157236e441dfac603b5fcb19ce8f393da6935a7dfb95be9e2b1b522"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
